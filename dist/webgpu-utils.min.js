!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports):"function"==typeof define&&define.amd?define(["exports"],t):t((e="undefined"!=typeof globalThis?globalThis:e||self).webgpuUtils={})}(this,function(e){"use strict";function t(){return e.noiseBuffer||(e.noiseBuffer=new P("noiseOffset",[1e3*Math.random(),1e3*Math.random(),1e3*Math.random()],"noiseOffset")),`\n    ${n}\n    ${r}\n    ${i}\n    `}e.noiseBuffer=void 0;const n="\nfn rand(n: f32) -> f32 { return fract(sin(438.347 * n / 10000)); }\nfn noise1(p: f32) -> f32 {\n  let pVal = p+noiseOffset.x;\n  let fl = floor(pVal);\n  let fc = fract(pVal);\n  return mix(rand(fl), rand(fl + 1.), fc);\n}\n",r="fn mod289(x: vec2<f32>) -> vec2<f32> {return x - floor(x * (1. / 289.)) * 289.;}\nfn mod289_3(x: vec3<f32>) -> vec3<f32> {return x - floor(x * (1. / 289.)) * 289.;}\nfn permute3(x: vec3<f32>) -> vec3<f32> {return mod289_3(((x * 34.) + 1.) * x);}\nfn noise2(v: vec2<f32>) -> f32 {\n  let v2 = v + noiseOffset.xy;\n  let C = vec4(\n      0.211324865405187, // (3.0-sqrt(3.0))/6.0\n      0.366025403784439, // 0.5*(sqrt(3.0)-1.0)\n      -0.577350269189626, // -1.0 + 2.0 * C.x\n      0.024390243902439 // 1.0 / 41.0\n  );\n  var i = floor(v2 + dot(v2, C.yy));\n  let x0 = v2 - i + dot(i, C.xx);\n  var i1 = select(vec2(0., 1.), vec2(1., 0.), x0.x > x0.y);\n  var x12 = x0.xyxy + C.xxzz;\n  x12.x = x12.x - i1.x;\n  x12.y = x12.y - i1.y;\n  i = mod289(i); // Avoid truncation effects in permutation\n  var p = permute3(permute3(i.y + vec3(0., i1.y, 1.)) + i.x + vec3(0., i1.x, 1.));\n  var m = max(0.5 - vec3(dot(x0, x0), dot(x12.xy, x12.xy), dot(x12.zw, x12.zw)), vec3(0.));\n  m *= m;\n  m *= m;\n  let x = 2. * fract(p * C.www) - 1.;\n  let h = abs(x) - 0.5;\n  let ox = floor(x + 0.5);\n  let a0 = x - ox;\n  m *= 1.79284291400159 - 0.85373472095314 * (a0 * a0 + h * h);\n  let g = vec3(a0.x * x0.x + h.x * x0.y, a0.yz * x12.xz + h.yz * x12.yw);\n  return 130. * dot(m, g);\n}",i="\nfn mod289_f(x: f32) -> f32 { return x - floor(x * (1.0 / 289.0)) * 289.0; }\nfn mod289_vec3(x: vec3<f32>) -> vec3<f32> { return x - floor(x * (1.0 / 289.0)) * 289.0; }\nfn mod289_vec4(x: vec4<f32>) -> vec4<f32> { return x - floor(x * (1.0 / 289.0)) * 289.0; }\nfn permute_vec4(x: vec4<f32>) -> vec4<f32> { return mod289_vec4(((x * 34.0) + 1.0) * x); }\nfn taylorInvSqrt_f(r: f32) -> f32 { return 1.79284291400159 - 0.85373472095314 * r; }\nfn taylorInvSqrt_vec4(r: vec4<f32>) -> vec4<f32> { return 1.79284291400159 - 0.85373472095314 * r; }\n\nfn noise3(_v: vec3<f32>) -> f32 {\n  let v = _v + noiseOffset.xyz;\n  let C = vec4<f32>(\n    0.1381966, // 1/6\n    0.2763932, // 1/3\n    0.5,\n    -0.5\n  );\n  \n  // First corner\n  var i = floor(v + dot(v, C.yyy));\n  let x0 = v - i + dot(i, C.xxx);\n  \n  // Other corners\n  let g = step(x0.yzx, x0.xyz);\n  let l = 1.0 - g;\n  let i1 = min(g.xyz, l.zxy);\n  let i2 = max(g.xyz, l.zxy);\n  \n  let x1 = x0 - i1 + C.xxx;\n  let x2 = x0 - i2 + C.yyy;\n  let x3 = x0 - 0.5;\n  \n  // Permutations\n  i = mod289_vec3(i); // Avoid truncation effects in permutation\n  let p = permute_vec4(permute_vec4(permute_vec4(\n    i.z + vec4<f32>(0.0, i1.z, i2.z, 1.0))\n    + i.y + vec4<f32>(0.0, i1.y, i2.y, 1.0))\n    + i.x + vec4<f32>(0.0, i1.x, i2.x, 1.0));\n    \n  // Gradients: 7x7 points over a square, mapped onto an octahedron.\n  // The ring size 17*17 = 289 is close to a multiple of 49 (49*6 = 294)\n  let j = p - 49.0 * floor(p * (1.0 / 49.0));  // mod(p,7*7)\n  \n  let x_ = floor(j * (1.0 / 7.0));\n  let y_ = floor(j - 7.0 * x_);  // mod(j,N)\n  \n  let x = x_ * (2.0 / 7.0) + 0.5 / 7.0 - 1.0;\n  let y = y_ * (2.0 / 7.0) + 0.5 / 7.0 - 1.0;\n  \n  let h = 1.0 - abs(x) - abs(y);\n  \n  let b0 = vec4<f32>(x.xy, y.xy);\n  let b1 = vec4<f32>(x.zw, y.zw);\n  \n  let s0 = floor(b0) * 2.0 + 1.0;\n  let s1 = floor(b1) * 2.0 + 1.0;\n  let sh = -step(h, vec4<f32>(0.0));\n  \n  let a0 = b0.xzyw + s0.xzyw * sh.xxyy;\n  let a1 = b1.xzyw + s1.xzyw * sh.zzww;\n  \n  var p0 = vec3<f32>(a0.xy, h.x);\n  var p1 = vec3<f32>(a0.zw, h.y);\n  var p2 = vec3<f32>(a1.xy, h.z);\n  var p3 = vec3<f32>(a1.zw, h.w);\n  \n  // Normalise gradients\n  let norm = taylorInvSqrt_vec4(vec4<f32>(dot(p0, p0), dot(p1, p1), dot(p2, p2), dot(p3, p3)));\n  p0 *= norm.x;\n  p1 *= norm.y;\n  p2 *= norm.z;\n  p3 *= norm.w;\n  \n  // Mix final noise value\n  var m = max(0.6 - vec4<f32>(dot(x0, x0), dot(x1, x1), dot(x2, x2), dot(x3, x3)), vec4<f32>(0.0));\n  m = m * m;\n  return 42.0 * dot(m * m, vec4<f32>(dot(p0, x0), dot(p1, x1), dot(p2, x2), dot(p3, x3)));\n}\n";class o{constructor(e,t=[]){if("string"!=typeof e||""===e.trim())throw new Error("Struct: Name must be a non-empty string");if(this.name=e,this.data=t,this.floatSize%4!=0){const e=4-this.floatSize%4;for(let t=0;t<e;t++)this.data.push({name:`FILLER___${t}`,type:a})}}add(e,t){if("string"!=typeof e||""===e.trim())throw new Error("Struct.add: Field name must be a non-empty string");if(!t||"object"!=typeof t||!("size"in t))throw new Error("Struct.add: Invalid type provided");this.data.push({name:e,type:t})}get byteSize(){return this.data.reduce((e,t)=>e+t.type.size,0)}get floatSize(){return this.byteSize/4}get code(){let e="struct "+this.name+" {\n";return this.data.forEach(({name:t,type:n})=>{e+=n.code(t)+",\n"}),e=e.slice(0,-2),e+"\n};"}object(){const e={};return this.data.forEach(({name:t,type:n})=>{e[t]=n.object()}),e}toFloat32Array(e){if(!e)throw new Error("Struct.toFloat32Array: Input values are required");e instanceof Array||(e=[e]);const t=new Float32Array(this.floatSize*e.length);let n=0;return e.forEach((e,r)=>{if(!e||"object"!=typeof e)throw new Error(`Struct.toFloat32Array: Invalid value at index ${r}`);this.data.forEach(({name:i,type:o})=>{const a=e[i];if(void 0===a)throw new Error(`Struct.toFloat32Array: Missing field ${i} at index ${r}`);t.set(o.toFloat32Array(a),n),n+=o.size/4})}),t}fromFloat32Array(e){if(!(e instanceof Float32Array))throw new Error("Struct.fromFloat32Array: Input must be a Float32Array");const t=[];let n=0;for(;n<e.length;){const r={};this.data.forEach(({name:t,type:i})=>{if(n+i.size/4>e.length)throw new Error("Struct.fromFloat32Array: Array too short for struct layout");r[t]=i.fromFloat32Array(e.slice(n,n+i.size/4)),n+=i.size/4}),t.push(r)}return t}createBuffer(e,t){if(!t)throw new Error("Struct.createBuffer: Values are required");if(!Array.isArray(t)){const n=new P(e,this.toFloat32Array([t]));return n.struct=this,n}if(t.length<1)throw new Error("Struct.createBuffer: Empty values array");if(t.length<65e3)try{const n=new P(e,this.toFloat32Array(t));return n.struct=this,n.isArray=!0,n}catch(e){throw new Error(`Struct.createBuffer: Failed to create buffer: ${e.message}`)}const n=[];for(let r=0;r<t.length;r+=65e3){const i=t.slice(r,r+65e3);try{const t=new P(e,this.toFloat32Array(i));t.count=i.length,t.struct=this,t.isArray=!0,n.push(t)}catch(e){throw new Error(`Struct.createBuffer: Failed to create buffer chunk ${r}: ${e.message}`)}}return n}}const a={size:4,toFloat32Array:e=>{if("number"!=typeof e)throw new Error("type_f32.toFloat32Array: Expected a number");return new Float32Array([e])},fromFloat32Array:e=>e[0],code:e=>`${e}: f32`,object:()=>0},s={size:8,toFloat32Array:e=>{if(!e||"object"!=typeof e||!("x"in e)||!("y"in e))throw new Error("type_vec2.toFloat32Array: Expected an object with x and y properties");return new Float32Array([e.x,e.y])},fromFloat32Array:e=>({x:e[0],y:e[1]}),code:e=>`${e}: vec2<f32>`,object:()=>({x:0,y:0})},c={size:12,toFloat32Array:e=>{if(!(e&&"object"==typeof e&&"x"in e&&"y"in e&&"z"in e))throw new Error("type_vec3.toFloat32Array: Expected an object with x, y, and z properties");return new Float32Array([e.x,e.y,e.z])},fromFloat32Array:e=>({x:e[0],y:e[1],z:e[2]}),code:e=>`${e}: vec3<f32>`,object:()=>({x:0,y:0,z:0})},f={size:16,toFloat32Array:e=>{if(!(e&&"object"==typeof e&&"x"in e&&"y"in e&&"z"in e&&"w"in e))throw new Error("type_vec4.toFloat32Array: Expected an object with x, y, z, and w properties");return new Float32Array([e.x,e.y,e.z,e.w])},fromFloat32Array:e=>({x:e[0],y:e[1],z:e[2],w:e[3]}),code:e=>`${e}: vec4<f32>`,object:()=>({x:0,y:0,z:0,w:0})},l={size:16,toFloat32Array:e=>{if(!(e&&"object"==typeof e&&"r"in e&&"g"in e&&"b"in e&&"a"in e))throw new Error("type_color.toFloat32Array: Expected an object with r, g, b, and a properties");return new Float32Array([e.r,e.g,e.b,e.a])},fromFloat32Array:e=>({r:e[0],g:e[1],b:e[2],a:e[3]}),code:e=>`${e}: vec4<f32>`,object:()=>({r:0,g:0,b:0,a:1})},d=(e=1,t=0)=>Math.random()*(e-t)+t;function u(){if(!e.canvas)throw new Error("createMouseBuffer: Canvas is not defined");const t=new o("mouseStruct",[{name:"pos",type:s},{name:"button",type:a}]);e.mouseBuffer=t.createBuffer("mouse",t.object());const n=t=>{const n=e.canvas.getBoundingClientRect(),r=1==t.buttons?0:1;e.mouseBuffer.update(new Float32Array([e.width*(t.clientX-n.left)/n.width,e.height*(t.clientY-n.top)/n.height,r]))};document.addEventListener("mousemove",n),document.addEventListener("mousedown",n),document.addEventListener("mouseup",n)}function h(){return e.timeBuffer=new P("time",new Float32Array([0])),setInterval(()=>{e.timeBuffer.update(new Float32Array([performance.now()/1e3]))},1e3/60),e.timeBuffer}e.mouseBuffer=null,e.timeBuffer=null;class p{constructor(t,n){if(!e.device)throw new Error("RenderPass: WebGPU device not initialized. Call initCanvas() first.");if(!t||"object"!=typeof t)throw new Error("RenderPass: Invalid texture");if("string"!=typeof n||""===n.trim())throw new Error("RenderPass: Shader code must be a non-empty string");try{this.module=e.device.createShaderModule({code:n}),this.pipeline=e.device.createRenderPipeline({layout:"auto",vertex:{module:this.module,entryPoint:"vs"},fragment:{module:this.module,entryPoint:"fs",targets:[{format:e.canvasPresentationFormat}]}}),this.sampler=e.device.createSampler({magFilter:"linear",minFilter:"linear"}),this.bindGroup=e.device.createBindGroup({layout:this.pipeline.getBindGroupLayout(0),entries:[{binding:0,resource:this.sampler},{binding:1,resource:t.resource}]}),this.renderPassDescriptor={colorAttachments:[{clearValue:[0,0,0,1],loadOp:"clear",storeOp:"store"}]}}catch(e){throw new Error(`Failed to create RenderPass: ${e.message}`)}}run(t){try{this.renderPassDescriptor.colorAttachments[0].view=e.ctx.getCurrentTexture().createView();const n=t.beginRenderPass(this.renderPassDescriptor);n.setPipeline(this.pipeline),n.setBindGroup(0,this.bindGroup),n.draw(6),n.end()}catch(e){throw new Error(`Failed to run RenderPass: ${e.message}`)}}}class v{constructor(t,n,r,i="main"){if([{binding:e.mouseBuffer,regex:/\bmouse(\.(pos|button))?\b/},{binding:e.timeBuffer,regex:/\btime\b/},{binding:e.renderTxtr,regex:/\brenderTxtr\b/,function:"write"},{binding:e.feedbackTxtr,regex:/\bfeedbackTxtr\b/,function:"read"}].forEach(e=>{if(t.match(e.regex)&&!n.some(t=>t.name===e.binding.name)){const t=e.function?e.binding[e.function]():e.binding;n.push(t)}}),/\bnoise\s*\(|\bnoise2\s*\(|\bnoise3\s*\(/.test(t)&&e.noiseBuffer&&n.push(e.noiseBuffer),n.some(e=>Array.isArray(e))){const e=n.find(e=>Array.isArray(e)),r=n.findIndex(e=>Array.isArray(e));return e.map((e,o)=>{const a=n.slice();return a[r]=e,new v(t,a,e.count,i)})}let o="";n.forEach((e,t)=>{o+=e.getBindingCode(t)+"\n"}),t=o+t,n.forEach(e=>{e.struct&&(t=e.struct.code+"\n"+t)}),this.code=t,this.module=e.device.createShaderModule({code:t}),this.pipeline=e.device.createComputePipeline({layout:"auto",compute:{module:this.module,entryPoint:i}}),this.bindGroup=e.device.createBindGroup({layout:this.pipeline.getBindGroupLayout(0),entries:n.map((e,t)=>({binding:t,resource:e.resource}))}),this.dispatchSize=r,Array.isArray(r)||(this.dispatchSize=[r])}run(e){const t=e.beginComputePass();t.setPipeline(this.pipeline),t.setBindGroup(0,this.bindGroup),t.dispatchWorkgroups(...this.dispatchSize),t.end()}static texture(t,n){return new v(t,n,[e.width,e.height])}static compute(e,t,n){return new v(e,t,[n.length])}}function m(t,n=1){if(!e.device)throw new Error("runPasses: WebGPU device not initialized. Call initCanvas() first.");Array.isArray(t)||(t=[t]);try{const r=e.device.createCommandEncoder();for(let e=0;e<n;e++)for(const e of t)if(Array.isArray(e))e.forEach(e=>{if(!e||"function"!=typeof e.run)throw new Error("Invalid pass object in array");e.run(r)});else{if(!e||"function"!=typeof e.run)throw new Error("Invalid pass object");e.run(r)}e.device.queue.submit([r.finish()])}catch(e){throw new Error(`Failed to run passes: ${e.message}`)}}const x={bgColor:[0,0,0]};async function y(t={}){return t.bgColor&&(x.bgColor=t.bgColor),await g(),b(),e.renderPass=new p(e.renderTxtr,w),e.renderPass}async function g(){try{e.renderTxtr=new C("renderTxtr",e.width,e.height),e.feedbackTxtr=new C("feedbackTxtr",e.width,e.height);const t=`\n        @compute @workgroup_size(1)\n        fn main(@builtin(global_invocation_id) id: vec3<u32>) {\n          let x: i32 = i32(id.x);\n          let y: i32 = i32(id.y);\n          let clr = vec4f(${x.bgColor[0]/255},${x.bgColor[1]/255},${x.bgColor[2]/255},1.0);\n          textureStore(renderTxtr, vec2<i32>(x, y), clr);\n          textureStore(feedbackTxtr, vec2<i32>(x, y), clr);\n        }`;m([new v(t,[e.renderTxtr.write(),e.feedbackTxtr.write()],[e.width,e.height])])}catch(e){throw new Error(`Failed to create textures: ${e.message}`)}}e.renderTxtr=void 0,e.feedbackTxtr=void 0,e.renderPass=void 0,e.matchPass=void 0,e.clearPass=void 0;const w="\n    struct OurVertexShaderOutput {\n        @builtin(position) position: vec4f,\n        @location(0) uv: vec2f,\n    };\n\n    @vertex fn vs(@builtin(vertex_index) vertexIndex: u32) -> OurVertexShaderOutput {\n        let pos = array(\n            vec2f(-1.0, -1.0), vec2f(1.0, -1.0),\n            vec2f(-1.0, 1.0), vec2f(-1.0, 1.0),\n            vec2f(1.0, -1.0), vec2f(1.0, 1.0),\n        );\n\n        var vsOutput: OurVertexShaderOutput;\n        let xy = pos[vertexIndex];\n        vsOutput.position = vec4f(xy, 0.0, 1.0);\n        vsOutput.uv = vec2f((xy.x + 1.0) / 2.0, 1.0-(xy.y + 1.0) / 2.0);\n        return vsOutput;\n    }\n\n    @group(0) @binding(0) var ourSampler: sampler;\n    @group(0) @binding(1) var ourTexture: texture_2d<f32>;\n\n    @fragment fn fs(fsInput: OurVertexShaderOutput) -> @location(0) vec4f {\n        return textureSample(ourTexture, ourSampler, fsInput.uv);\n    }\n    ";async function A(){if(!e.renderTxtr||!e.feedbackTxtr)throw new Error("createMatchPass: Textures must be created first with createTextures()");return e.matchPass=new v("\n    @compute @workgroup_size(1)\n    fn main(@builtin(global_invocation_id) id: vec3<u32>) {\n      let x: i32 = i32(id.x);\n      let y: i32 = i32(id.y);\n      let clr = textureLoad(renderTxtr, vec2<i32>(x, y), 0);\n      textureStore(feedbackTxtr, vec2<i32>(x, y), vec4<f32>(clr.r, clr.g, clr.b, 1.0));\n    }",[e.renderTxtr.read(),e.feedbackTxtr.write()],[e.width,e.height]),e.matchPass}async function b(){if(!e.renderTxtr||!e.feedbackTxtr)throw new Error("createClearPass: Textures must be created first with createTextures()");const t=`\n    @compute @workgroup_size(1)\n    fn main(@builtin(global_invocation_id) id: vec3<u32>) {\n      let x: i32 = i32(id.x);\n      let y: i32 = i32(id.y);\n\n      var clr = vec4<f32>(${x.bgColor[0]/255}, ${x.bgColor[1]/255}, ${x.bgColor[2]/255}, 1.0);\n\n      textureStore(renderTxtr, vec2<i32>(x, y), clr);\n      textureStore(feedbackTxtr, vec2<i32>(x, y), clr);\n    }`;return e.clearPass=new v(t,[e.renderTxtr.write(),e.feedbackTxtr.write()],[e.width,e.height]),e.clearPass}async function E(t={}){if(!navigator.gpu)throw new Error("WebGPU not supported in this browser.");try{const n=await(navigator.gpu?.requestAdapter());if(!n)throw new Error("Couldn't request WebGPU adapter.");if(e.device=await n.requestDevice(),!e.device)throw new Error("Couldn't request WebGPU device.");e.device.addEventListener("uncapturederror",e=>{console.error("WebGPU device error:",e.error)}),e.canvas=t.canvas||document.querySelector("canvas"),e.canvas||(e.canvas=document.createElement("canvas"));let r=null;if(t.containerId){if(r=document.getElementById(t.containerId),!r)throw new Error(`Container with ID '${t.containerId}' not found.`);r.appendChild(e.canvas),e.width=r.clientWidth,e.height=r.clientHeight,e.canvas.style.display="block"}else t.canvas||document.body.appendChild(e.canvas),e.width=window.innerWidth,e.height=window.innerHeight;if(t.width&&(e.width=t.width),t.height&&(e.height=t.height),e.canvas.style.width=e.width+"px",e.canvas.style.height=e.height+"px",e.width*=2,e.height*=2,e.canvas.width=e.width,e.canvas.height=e.height,e.ctx=e.canvas.getContext("webgpu"),!e.ctx)throw new Error("Couldn't get WebGPU context from canvas.");return e.canvasPresentationFormat=navigator.gpu.getPreferredCanvasFormat(),e.ctx.configure({device:e.device,format:e.canvasPresentationFormat,alphaMode:"premultiplied"}),window.addEventListener("keydown",t=>{if("s"===t.key){const t=document.createElement("a");t.href=e.canvas.toDataURL(),t.download="webgpu-image-"+(new Date).toISOString().replace(/:/g,"-")+".png",t.click()}}),{device:e.device,canvas:e.canvas,width:e.width,height:e.height}}catch(e){throw new Error(`Failed to initialize canvas: ${e.message}`)}}function _(){return new Promise(e=>{"complete"===document.readyState||"interactive"===document.readyState?e():document.addEventListener("DOMContentLoaded",()=>e())})}e.width=void 0,e.height=void 0,e.device=void 0,e.canvas=void 0,e.canvasPresentationFormat=void 0,e.ctx=void 0;class P{constructor(t,n){if(!e.device)throw new Error("Buffer: WebGPU device not initialized. Call initCanvas() first.");try{if(this.name=t,Array.isArray(n))n=new Float32Array(n);else if(!(n instanceof Float32Array))throw new Error("Buffer: Data must be an Array or Float32Array");this.data=n,this.size=n.byteLength,this.buffer=e.device.createBuffer({label:this.name,size:this.size,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_DST|GPUBufferUsage.COPY_SRC,mappedAtCreation:!0}),new Float32Array(this.buffer.getMappedRange()).set(n),this.buffer.unmap(),this.resource={buffer:this.buffer}}catch(e){throw new Error(`Failed to create Buffer: ${e.message}`)}}update(t){if(!t||!Array.isArray(t)&&!(t instanceof Float32Array))throw new Error("Buffer.update: Data must be an Array or Float32Array");try{Array.isArray(t)&&(t=new Float32Array(t)),e.device.queue.writeBuffer(this.buffer,0,t),this.data=t}catch(e){throw new Error(`Failed to update Buffer: ${e.message}`)}}getBindingCode(e){if(!this.resource||!this.resource.buffer)throw new Error("Buffer.getBindingCode: Buffer resource not initialized");let t="f32";return this.struct?t=this.struct.name:4==this.size?t="f32":8==this.size?t="vec2f":12==this.size?t="vec3f":16==this.size&&(t="vec4f"),this.isArray&&(t=`array<${t}>`),`@group(0) @binding(${e}) var<storage, read_write> ${this.name}: ${t};`}async getData(){const t=e.device.createBuffer({size:this.size,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ}),n=e.device.createCommandEncoder();n.copyBufferToBuffer(this.buffer,0,t,0,this.size);const r=n.finish();e.device.queue.submit([r]),await t.mapAsync(GPUMapMode.READ);const i=t.getMappedRange(),o=[...new Float32Array(i)];return t.unmap(),o}}class C{constructor(t="",n=512,r=512,i="rgba8unorm"){if(!e.device)throw new Error("Texture: WebGPU device not initialized. Call initCanvas() first.");try{this.name=t,this.width=n,this.height=r,this.format=i,this.texture=e.device.createTexture({label:this.name,size:[n,r,1],format:i,usage:GPUTextureUsage.COPY_DST|GPUTextureUsage.STORAGE_BINDING|GPUTextureUsage.TEXTURE_BINDING}),this.view=this.texture.createView(),this.resource=this.view}catch(e){throw new Error(`Failed to create Texture: ${e.message}`)}}read(){return new z(this,"read")}write(){return new z(this,"write")}}function z(e,t="read"){this.texture=e,this.readOrWrite=t,this.resource=e.resource,this.name=e.name,this.getBindingCode=e=>"read"===this.readOrWrite&&"rgba8unorm"==this.texture.format?`@group(0) @binding(${e}) var ${this.texture.name}: texture_2d<f32>;`:`@group(0) @binding(${e}) var ${this.texture.name}: texture_storage_2d<${this.texture.format}, ${this.readOrWrite}>;`}e.cameraCode="\n  let theta = 0.0;\n  let camPos = vec3<f32>(0.0, 0.0, 1000.0);\n";class S{constructor(e){this.code=e,this.position=0,this.functions=[],this.body=[]}peek(e=0){return this.code[this.position+e]||""}advance(){return this.code[this.position++]||""}skipWhitespace(){for(;this.position<this.code.length&&/\s/.test(this.peek());)this.advance()}skipComment(){if("/"===this.peek()&&"/"===this.peek(1)){for(;this.position<this.code.length&&"\n"!==this.peek();)this.advance();return!0}if("/"===this.peek()&&"*"===this.peek(1)){for(this.advance(),this.advance();this.position<this.code.length-1;){if("*"===this.peek()&&"/"===this.peek(1)){this.advance(),this.advance();break}this.advance()}return!0}return!1}skipWhitespaceAndComments(){let e=!0;for(;e;){const t=this.position;this.skipWhitespace(),this.skipComment(),e=this.position>t}}readIdentifier(){let e="";for(;this.position<this.code.length&&/[a-zA-Z0-9_]/.test(this.peek());)e+=this.advance();return e}matchKeyword(e){const t=this.position;this.skipWhitespaceAndComments();for(let n=0;n<e.length;n++){if(this.peek()!==e[n])return this.position=t,!1;this.advance()}return!/[a-zA-Z0-9_]/.test(this.peek())||(this.position=t,!1)}findMatchingBrace(){if("{"!==this.peek())return-1;this.position,this.advance();let e=1;for(;this.position<this.code.length&&e>0;)if(this.skipWhitespaceAndComments(),"{"===this.peek())e++,this.advance();else if("}"===this.peek())e--,this.advance();else if('"'===this.peek()){for(this.advance();this.position<this.code.length&&'"'!==this.peek();)"\\"===this.peek()&&this.advance(),this.advance();'"'===this.peek()&&this.advance()}else this.advance();return 0===e?this.position:-1}parseFunction(){const e=this.position;if(!this.matchKeyword("fn"))return null;this.skipWhitespaceAndComments();if(!this.readIdentifier())return this.position=e,null;if(this.skipWhitespaceAndComments(),"("!==this.peek())return this.position=e,null;let t=1;for(this.advance();this.position<this.code.length&&t>0;)"("===this.peek()?t++:")"===this.peek()&&t--,this.advance();if(this.skipWhitespaceAndComments(),"-"===this.peek()&&">"===this.peek(1))for(this.advance(),this.advance(),this.skipWhitespaceAndComments();this.position<this.code.length&&"{"!==this.peek()&&!/\s/.test(this.peek());)if("<"===this.peek()){let e=1;for(this.advance();this.position<this.code.length&&e>0;)"<"===this.peek()?e++:">"===this.peek()&&e--,this.advance()}else this.advance();this.skipWhitespaceAndComments();const n=this.findMatchingBrace();if(-1===n)return this.position=e,null;return this.code.slice(e,n).trim()}parse(){for(;this.position<this.code.length&&(this.skipWhitespaceAndComments(),!(this.position>=this.code.length));){const e=this.parseFunction();if(e)this.functions.push(e);else{const e=this.position;for(;this.position<this.code.length&&"\n"!==this.peek();)this.advance();"\n"===this.peek()&&this.advance();const t=this.code.slice(e,this.position).trim();t&&this.body.push(t)}}return{functions:this.functions,body:this.body.join("\n")}}}function T(e){try{return new S(e).parse()}catch(t){console.warn("Parser failed, falling back to simple approach:",t);const n=e.split("\n").map(e=>e.trim()).filter(e=>e),r=[],i=[];let o=!1,a=0,s=[];for(const e of n)e.startsWith("fn ")?(o=!0,s=[e],a=(e.match(/\{/g)||[]).length-(e.match(/\}/g)||[]).length):o?(s.push(e),a+=(e.match(/\{/g)||[]).length-(e.match(/\}/g)||[]).length,0===a&&(r.push(s.join("\n")),o=!1,s=[])):i.push(e);return{functions:r,body:i.join("\n")}}}class F{constructor(){this.functions=[],this.bindings=[],this.structs=[]}fn(e,t,n,r){const i=`fn ${e}(${t}) -> ${n} {\n${r}\n}`;return this.functions.push(i),this}binding(e,t,n,r){return this.bindings.push(`@group(${e}) @binding(${t}) var ${r}: ${n};`),this}struct(e,t){return this.structs.push(`struct ${e} {\n${t}\n}`),this}get main(){return(e,...t)=>{let n="";this.bindings.length>0&&(n+=this.bindings.join("\n")+"\n\n"),this.structs.length>0&&(n+=this.structs.join("\n\n")+"\n\n"),this.functions.length>0&&(n+=this.functions.join("\n\n")+"\n\n");if(n+=String.raw({raw:e},...t),/fn\s+main\s*\(/.test(n))return n;const{functions:r,body:i}=T(n);let o="";if(r.length>0&&(o+=r.join("\n\n")+"\n\n"),o+="@compute @workgroup_size(1)\n",o+="fn main(@builtin(global_invocation_id) id: vec3<u32>) {\n",i){o+=i.split("\n").map(e=>e.trim()?"  "+e:e).join("\n")+"\n"}return o+="}",o}}}function R(n,...r){let i=String.raw({raw:n},...r);if(i=i.replace(/\bwidth\b/g,e.width.toFixed(2)),i=i.replace(/\bheight\b/g,e.height.toFixed(2)),/\bnoise\s*\(|\bnoise2\s*\(|\bnoise3\s*\(/.test(i)&&(/fn\s+noise\s*\(/.test(i)||/fn\s+noise2\s*\(/.test(i)||/fn\s+noise3\s*\(/.test(i)||(i=t()+"\n\n"+i)),i=i.trim(),/fn\s+main\s*\(/.test(i))return i;const{functions:o,body:a}=T(i);let s="";if(o.length>0&&(s+=o.join("\n\n")+"\n\n"),s+="@compute @workgroup_size(1)\n",s+="fn main(@builtin(global_invocation_id) id: vec3<u32>) {\n",a){s+=a.split("\n").map(e=>e.trim()?"  "+e:e).join("\n")+"\n"}return s+="}",s}R.compute=()=>new F,R.setWidth=e=>{R.width=e};e.Buffer=P,e.ComputePass=v,e.RenderPass=p,e.Struct=o,e.Texture=C,e.VERSION="0.1.0",e.basicRenderCode=w,e.choose=e=>{if(!Array.isArray(e))throw new Error("choose: Expected an array as argument");if(0===e.length)throw new Error("choose: Cannot select from an empty array");return e[Math.floor(d(e.length))]},e.createClearPass=b,e.createFirstPersonCamera=function(t={}){const{initialPosition:n={x:0,y:2,z:5},initialLookAt:r={x:0,y:0,z:0},moveSpeed:i=.1,sensitivity:o=.003}=t;return`\n    // First-person camera constants\n    const CAMERA_MOVE_SPEED = ${i};\n    const MOUSE_SENSITIVITY = ${o};\n    const FIELD_OF_VIEW = 70.0;\n    const ASPECT_RATIO = ${e.width/e.height};\n    const NEAR_PLANE = 0.1;\n    const FAR_PLANE = 1000.0;\n    const CAMERA_UP = vec3<f32>(0.0, 1.0, 0.0);\n    \n    // Camera state (should be fed from uniform buffer in real implementation)\n    var<private> camera_position = vec3<f32>(${n.x}, ${n.y}, ${n.z});\n    var<private> camera_front = normalize(vec3<f32>(${r.x-n.x}, \n                                                   ${r.y-n.y},\n                                                   ${r.z-n.z}));\n    var<private> camera_right = normalize(cross(camera_front, CAMERA_UP));\n    var<private> camera_up = normalize(cross(camera_right, camera_front));\n    var<private> yaw = -90.0; // Default is looking along negative z\n    var<private> pitch = 0.0;\n    \n    fn updateCameraVectors() {\n        let direction = vec3<f32>(\n            cos(radians(yaw)) * cos(radians(pitch)),\n            sin(radians(pitch)),\n            sin(radians(yaw)) * cos(radians(pitch))\n        );\n        \n        camera_front = normalize(direction);\n        camera_right = normalize(cross(camera_front, CAMERA_UP));\n        camera_up = normalize(cross(camera_right, camera_front));\n    }\n    \n    fn moveCamera(direction: i32) {\n        switch direction {\n            case 0: { // Forward\n                camera_position += CAMERA_MOVE_SPEED * camera_front;\n            }\n            case 1: { // Backward\n                camera_position -= CAMERA_MOVE_SPEED * camera_front;\n            }\n            case 2: { // Left\n                camera_position -= CAMERA_MOVE_SPEED * camera_right;\n            }\n            case 3: { // Right\n                camera_position += CAMERA_MOVE_SPEED * camera_right;\n            }\n            case 4: { // Up\n                camera_position += CAMERA_MOVE_SPEED * CAMERA_UP;\n            }\n            case 5: { // Down\n                camera_position -= CAMERA_MOVE_SPEED * CAMERA_UP;\n            }\n            default: {}\n        }\n    }\n    \n    fn rotateCamera(xoffset: f32, yoffset: f32) {\n        yaw += xoffset * MOUSE_SENSITIVITY;\n        pitch += yoffset * MOUSE_SENSITIVITY;\n        \n        // Constrain pitch\n        pitch = clamp(pitch, -89.0, 89.0);\n        \n        updateCameraVectors();\n    }\n    \n    fn getViewMatrix() -> mat4x4<f32> {\n        let target = camera_position + camera_front;\n        return lookAt(camera_position, target, camera_up);\n    }\n    \n    fn lookAt(eye: vec3<f32>, target: vec3<f32>, up: vec3<f32>) -> mat4x4<f32> {\n        let f = normalize(target - eye);\n        let r = normalize(cross(f, up));\n        let u = cross(r, f);\n        \n        return mat4x4<f32>(\n            vec4<f32>(r.x, u.x, -f.x, 0.0),\n            vec4<f32>(r.y, u.y, -f.y, 0.0),\n            vec4<f32>(r.z, u.z, -f.z, 0.0),\n            vec4<f32>(-dot(r, eye), -dot(u, eye), dot(f, eye), 1.0)\n        );\n    }\n    \n    fn perspectiveMatrix() -> mat4x4<f32> {\n        let fovRad = radians(FIELD_OF_VIEW);\n        let f = 1.0 / tan(fovRad / 2.0);\n        \n        return mat4x4<f32>(\n            vec4<f32>(f / ASPECT_RATIO, 0.0, 0.0, 0.0),\n            vec4<f32>(0.0, f, 0.0, 0.0),\n            vec4<f32>(0.0, 0.0, (FAR_PLANE + NEAR_PLANE) / (NEAR_PLANE - FAR_PLANE), -1.0),\n            vec4<f32>(0.0, 0.0, (2.0 * FAR_PLANE * NEAR_PLANE) / (NEAR_PLANE - FAR_PLANE), 0.0)\n        );\n    }\n    \n    fn worldToScreenPerspective(worldPos: vec3<f32>) -> vec2<f32> {\n        let viewMatrix = getViewMatrix();\n        let projMatrix = perspectiveMatrix();\n        let viewProj = projMatrix * viewMatrix;\n        \n        // Transform to clip space\n        let clipPos = viewProj * vec4<f32>(worldPos, 1.0);\n        \n        // Perspective division\n        let ndcPos = clipPos.xyz / clipPos.w;\n        \n        // Convert to screen coordinates [0,1]\n        return vec2<f32>(\n            (ndcPos.x + 1.0) * 0.5,\n            (ndcPos.y + 1.0) * 0.5\n        );\n    }\n    `},e.createGetRayFunction=function(t={}){return`\nfn getRay(x: i32, y: i32) -> Ray {\n    ${t.customCameraCode||e.cameraCode}\n    camPos = rotate_y(camPos, theta);\n    let lookAt = vec3<f32>(0.0, 0.0, 0.0);\n    let forward = normalize(lookAt - camPos);\n\n    // Calculate right vector (perpendicular to forward and world up)\n    let worldUp = vec3<f32>(0.0, 1.0, 0.0);\n    let right = normalize(cross(forward, worldUp));\n\n    // Calculate camera's up vector\n    let up = normalize(cross(right, forward));\n\n    // Screen coordinates relative to center\n    let screenX = f32(x) / 2 - ${(t.width||globalThis.width||1e3)/4};\n    let screenY = f32(y) / 2 - ${(t.height||globalThis.height||1e3)/4};\n\n    // Scale factors to control orthographic view size\n    let orthoScale = 1.0; // Adjust as needed\n\n    // For orthographic, we offset the ray origin in the plane perpendicular to viewing direction\n    let ro = camPos + (right * screenX * orthoScale) + (up * screenY * orthoScale);\n\n    // All rays have the same direction (parallel)\n    let rd = forward;\n\n    return Ray(ro, rd);\n  }\n`},e.createMatchPass=A,e.createMouseBuffer=u,e.createRenderPass=y,e.createStaticCamera=function(t,n={x:0,y:0,z:0}){if(!t||"object"!=typeof t||"number"!=typeof t.x||"number"!=typeof t.y||"number"!=typeof t.z)throw new Error("createStaticCamera: Valid position object with x, y, z coordinates is required");return`\n    // Static camera configuration constants\n    const FIELD_OF_VIEW = 90.0;\n    const ASPECT_RATIO = ${e.width/e.height};\n    const NEAR_PLANE = 1.0;\n    const FAR_PLANE = 1000.0;\n    const CAMERA_UP = vec3 < f32 > (0.0, 1.0, 0.0);\n    \n    const CAMERA_POSITION = vec3<f32>(${t.x}, ${t.y}, ${t.z});\n    const CAMERA_TARGET = vec3<f32>(${n.x}, ${n.y}, ${n.z});\n\n    fn calculateCameraPosition() -> vec3 < f32 > {\n        return CAMERA_POSITION;\n    }\n\n    fn lookAt(eye: vec3 < f32 >, targetDir: vec3 < f32 >, up: vec3 < f32 >) -> mat4x4 < f32 > {\n        let f = normalize(targetDir - eye);\n        let s = normalize(cross(f, up));\n        let u = cross(s, f);\n\n        return mat4x4 < f32 > (\n            vec4 < f32 > (s.x, u.x, -f.x, 0.0),\n            vec4 < f32 > (s.y, u.y, -f.y, 0.0),\n            vec4 < f32 > (s.z, u.z, -f.z, 0.0),\n            vec4 < f32 > (-dot(s, eye), -dot(u, eye), dot(f, eye), 1.0)\n        );\n    }\n\n    fn perspectiveMatrix() -> mat4x4 < f32 > {\n        let fovRad = radians(FIELD_OF_VIEW);\n        let f = 1.0 / tan(fovRad / 2.0);\n\n        return mat4x4 < f32 > (\n            vec4 < f32 > (f / ASPECT_RATIO, 0.0, 0.0, 0.0),\n            vec4 < f32 > (0.0, f, 0.0, 0.0),\n            vec4 < f32 > (0.0, 0.0, (FAR_PLANE + NEAR_PLANE) / (NEAR_PLANE - FAR_PLANE), -1.0),\n            vec4 < f32 > (0.0, 0.0, (2.0 * FAR_PLANE * NEAR_PLANE) / (NEAR_PLANE - FAR_PLANE), 0.0)\n        );\n    }\n\n    fn worldToScreenPerspective(worldPos: vec3 < f32 >) -> vec2 < f32 > {\n        let cameraPos = calculateCameraPosition();\n        let viewMatrix = lookAt(cameraPos, CAMERA_TARGET, CAMERA_UP);\n        let projMatrix = perspectiveMatrix();\n        let viewProj = projMatrix * viewMatrix;\n\n        // Transform to clip space\n        let clipPos = viewProj * vec4 < f32 > (worldPos, 1.0);\n\n        // Perspective division\n        let ndcPos = clipPos.xyz / clipPos.w;\n\n        // Convert to screen coordinates [0,1]\n        return vec2 < f32 > (\n            (ndcPos.x + 1.0) * 0.5,\n            (ndcPos.y + 1.0) * 0.5\n        );\n    }\n    `},e.createTextures=g,e.createTimeBuffer=h,e.domReady=_,e.extractFunctionsAndBody=T,e.getCamStuff=function(t={}){const{cameraDistance:n=250,rotationSpeed:r=.01,fieldOfView:i=90,nearPlane:o=1,farPlane:a=1e3,cameraY:s=-100}=t;return`\n    // Camera configuration constants\n    const BASE_CAMERA_DISTANCE = ${n};\n    const ROTATION_SPEED = ${r};            // Adjust this to change rotation speed\n    const FIELD_OF_VIEW = ${i};\n    const ASPECT_RATIO = ${e.width/e.height};\n    const NEAR_PLANE = ${o};\n    const FAR_PLANE = ${a};\n    const CAMERA_UP = vec3 < f32 > (0.0, 1.0, 0.0);\n\n    // Orthographic parameters\n    const ORTHO_SIZE = 5.0;               // Size of the orthographic view (height)\n    const ORTHO_WIDTH = ORTHO_SIZE * ASPECT_RATIO;\n    const ORTHO_HEIGHT = ORTHO_SIZE;\n\n    fn calculateCameraPosition() -> vec3 < f32 > {\n        let angle = globalData[0].frame * ROTATION_SPEED;\n        return vec3 < f32 > (\n            cos(angle) * BASE_CAMERA_DISTANCE,\n            ${s},\n            sin(angle) * BASE_CAMERA_DISTANCE\n        );\n    }\n\n    fn lookAt(eye: vec3 < f32 >, targetDir: vec3 < f32 >, up: vec3 < f32 >) -> mat4x4 < f32 > {\n        let f = normalize(targetDir - eye);\n        let s = normalize(cross(f, up));\n        let u = cross(s, f);\n\n        return mat4x4 < f32 > (\n            vec4 < f32 > (s.x, u.x, -f.x, 0.0),\n            vec4 < f32 > (s.y, u.y, -f.y, 0.0),\n            vec4 < f32 > (s.z, u.z, -f.z, 0.0),\n            vec4 < f32 > (-dot(s, eye), -dot(u, eye), dot(f, eye), 1.0)\n        );\n    }\n\n    fn perspectiveMatrix() -> mat4x4 < f32 > {\n        let fovRad = radians(FIELD_OF_VIEW);\n        let f = 1.0 / tan(fovRad / 2.0);\n\n        return mat4x4 < f32 > (\n            vec4 < f32 > (f / ASPECT_RATIO, 0.0, 0.0, 0.0),\n            vec4 < f32 > (0.0, f, 0.0, 0.0),\n            vec4 < f32 > (0.0, 0.0, (FAR_PLANE + NEAR_PLANE) / (NEAR_PLANE - FAR_PLANE), -1.0),\n            vec4 < f32 > (0.0, 0.0, (2.0 * FAR_PLANE * NEAR_PLANE) / (NEAR_PLANE - FAR_PLANE), 0.0)\n        );\n    }\n\n    fn worldToScreenPerspective(worldPos: vec3 < f32 >) -> vec2 < f32 > {\n        let cameraPos = calculateCameraPosition();\n        let viewMatrix = lookAt(cameraPos, vec3 < f32 > (0.0, 0.0, 0.0), CAMERA_UP);\n        let projMatrix = perspectiveMatrix();\n        let viewProj = projMatrix * viewMatrix;\n\n        // Transform to clip space\n        let clipPos = viewProj * vec4 < f32 > (worldPos, 1.0);\n\n        // Perspective division\n        let ndcPos = clipPos.xyz / clipPos.w;\n\n        // Convert to screen coordinates [0,1]\n        return vec2 < f32 > (\n            (ndcPos.x + 1.0) * 0.5,\n            (ndcPos.y + 1.0) * 0.5\n        );\n    }\n    `},e.getNoiseCode=t,e.getTimeBuffer=function(){if(!e.timeBuffer)throw new Error("getTimeBuffer: Time buffer has not been created yet");return e.timeBuffer},e.init=async function(e={}){await _(),await E(e),e.mouse&&u(),e.time&&h(),y(),e.feedback&&A()},e.initCanvas=E,e.isWebGPUSupported=function(){return"undefined"!=typeof navigator&&navigator&&"gpu"in navigator},e.map=(e,t,n,r,i)=>r+(i-r)*(e-t)/(n-t),e.random=d,e.runPasses=m,e.setBackgroundColor=function(e){if(!Array.isArray(e)||e.length<3)throw new Error("setBackgroundColor: Expected an array of at least 3 RGB values [0-255]");x.bgColor=e.map(e=>Math.max(0,Math.min(255,e)))},e.setCameraCode=function(t){if("string"!=typeof t)throw new Error("setCameraCode: Camera code must be a string");e.cameraCode=t},e.timeout=async(e=10)=>new Promise(t=>setTimeout(t,e)),e.type_color=l,e.type_f32=a,e.type_vec2=s,e.type_vec3=c,e.type_vec4=f,e.wgsl=R,e.wgslFBM="\nfn fbm(p: vec2<f32>, octaves: i32) -> f32 {\n    var value = 0.0;\n    var amplitude = 0.5;\n    var frequency = 1.0;\n    var p2 = p + noiseOffset.xy * 10.0;\n    \n    for (var i = 0; i < octaves; i = i + 1) {\n        value += amplitude * noise2(p2 * frequency);\n        frequency *= 2.0;\n        amplitude *= 0.5;\n    }\n    \n    return value;\n}\n",e.wgslNoise=n,e.wgslNoise2=r,e.wgslNoise3=i,e.wgslVoronoi="\nfn voronoi(uv: vec2<f32>, scale: f32, seed: f32) -> f32 {\n    let s = scale;\n    let iuv = floor(uv * s);\n    let fuv = fract(uv * s);\n    var min_dist = 1.0;\n    \n    for (var y: i32 = -1; y <= 1; y = y + 1) {\n        for (var x: i32 = -1; x <= 1; x = x + 1) {\n            let neighbor = vec2<f32>(f32(x), f32(y));\n            let point = 0.5 + 0.5 * sin(seed + 6.2831 * rand(rand(iuv.x + neighbor.x + seed) + iuv.y + neighbor.y));\n            let diff = neighbor + point - fuv;\n            let dist = length(diff);\n            min_dist = min(min_dist, dist);\n        }\n    }\n    \n    return min_dist;\n}\n",e.wgsl_material="\nstruct Material {\n  albedo: vec3<f32>,\n  roughness: f32,\n  metallic: f32,\n  emission: vec3<f32>,\n  ior: f32,\n};\n\nfn defaultMaterial() -> Material {\n  return Material(\n    vec3<f32>(0.8, 0.8, 0.8), // albedo (diffuse color)\n    0.5,                       // roughness\n    0.0,                       // metallic\n    vec3<f32>(0.0, 0.0, 0.0), // emission\n    1.45                       // index of refraction\n  );\n}\n",e.wgsl_normals="\nfn sphereNormal(hitPos: vec3<f32>, sphere: sphere) -> vec3<f32> {\n  return normalize(hitPos - sphere.pos);\n}\n\nfn planeNormal(plane: Plane) -> vec3<f32> {\n  return plane.normal;\n}\n\nfn boxNormal(hitPos: vec3<f32>, box: Box) -> vec3<f32> {\n  // Find the face that was hit by checking which component is closest to the respective face\n  let center = (box.min + box.max) * 0.5;\n  let d = hitPos - center;\n  let s = (box.max - box.min) * 0.5;\n  \n  let bias = 0.0001; // Small bias to avoid precision errors\n  let nx = d.x / (s.x + bias);\n  let ny = d.y / (s.y + bias);\n  let nz = d.z / (s.z + bias);\n  \n  // Return normal for the face with largest value (closest to surface)\n  if (abs(nx) > abs(ny) && abs(nx) > abs(nz)) {\n    return vec3<f32>(sign(nx), 0.0, 0.0);\n  } else if (abs(ny) > abs(nz)) {\n    return vec3<f32>(0.0, sign(ny), 0.0);\n  } else {\n    return vec3<f32>(0.0, 0.0, sign(nz));\n  }\n}\n",e.wgsl_rayStruct="\n  struct hit {\n    dist: f32,\n    index: i32,\n  };\n\n  struct Ray {\n    ro: vec3<f32>,\n    rd: vec3<f32>,\n  };",e.wgsl_rayToBox="\nstruct Box {\n  min: vec3<f32>,\n  max: vec3<f32>,\n};\n\nfn rayToBox(ro: vec3<f32>, rd: vec3<f32>, box: Box) -> f32 {\n  let tMin = (box.min - ro) / rd;\n  let tMax = (box.max - ro) / rd;\n  \n  let t1 = min(tMin, tMax);\n  let t2 = max(tMin, tMax);\n  \n  let tNear = max(max(t1.x, t1.y), t1.z);\n  let tFar = min(min(t2.x, t2.y), t2.z);\n  \n  // Box is behind the ray or ray misses box\n  if (tNear > tFar || tFar < 0.0) {\n    return -1.0;\n  }\n  \n  // Return nearest positive hit\n  return tNear > 0.0 ? tNear : tFar;\n}\n\nfn isInBox(pos: vec3<f32>, box: Box) -> bool {\n  return all(pos >= box.min) && all(pos <= box.max);\n}\n",e.wgsl_rayToPlane="\nstruct Plane {\n  normal: vec3<f32>,\n  distance: f32,\n};\n\nfn rayToPlane(ro: vec3<f32>, rd: vec3<f32>, plane: Plane) -> f32 {\n  let denom = dot(plane.normal, rd);\n  \n  // Check if ray is parallel to the plane\n  if (abs(denom) < 0.0001) {\n    return -1.0;\n  }\n  \n  let t = -(dot(ro, plane.normal) + plane.distance) / denom;\n  \n  // Only return positive intersection distance (in front of the ray)\n  if (t < 0.0) {\n    return -1.0;\n  }\n  \n  return t;\n}\n",e.wgsl_rayToSphere="\nfn rayToSphere(ro: vec3<f32>, rd: vec3<f32>, sph: sphere) -> f32 {\n    let oc = ro - sph.pos;\n    // Since rd is typically normalized, a = dot(rd,rd) = 1.0\n    \n    let b = dot(oc, rd);\n    let c = dot(oc, oc) - sph.r * sph.r;\n    let discriminant = b * b - c;\n    \n    if (discriminant < 0.0) {\n        return -1.0;\n    }\n\n    let t1 = -b - sqrt(discriminant);\n    let t2 = -b + sqrt(discriminant);\n\n    if (t1 > 0.0) {\n      return t1;\n    }\n    if (t2 > 0.0) {\n      return t2;\n    } else {\n      return -1.0;\n    }\n}\nfn isInSphere(pos: vec3<f32>, sph: sphere) -> bool {\n  return length(pos - sph.pos) <= sph.r;\n}\n",e.wgsl_rotate="fn rotate(v: vec2<f32>, a: f32) -> vec2<f32> {\n    let s = sin(a);\n    let c = cos(a);\n    return vec2<f32>(c * v.x - s * v.y, s * v.x + c * v.y);\n    }",e.wgsl_rotate_y="fn rotate_y(vec: vec3<f32>, angle: f32) -> vec3<f32> {\n      let cos_theta = cos(angle);\n      let sin_theta = sin(angle);\n      return vec3<f32>(\n          vec.x * cos_theta + vec.z * sin_theta,\n          vec.y,\n          -vec.x * sin_theta + vec.z * cos_theta\n      );\n  }",Object.defineProperty(e,"__esModule",{value:!0})});
//# sourceMappingURL=webgpu-utils.min.js.map
